{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/flower17/Participants_Data/sample_submission.csv\n/kaggle/input/flower17/Participants_Data/Train.csv\n/kaggle/input/flower17/Participants_Data/Test.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import *\nfrom sklearn.preprocessing import *\nfrom sklearn.metrics import *\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nimport gc\nfrom tqdm import *","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/flower17/Participants_Data/Train.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv('/kaggle/input/flower17/Participants_Data/Test.csv')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss=pd.read_csv('/kaggle/input/flower17/Participants_Data/sample_submission.csv')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train, test]).reset_index(drop = True)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.nunique()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"Area_Code        30900\nLocality_Code       22\nRegion_Code       2185\nHeight             110\nDiameter           151\nClass                8\nSpecies            263\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Region_Species'] = pd.factorize(df['Region_Code'].astype('str') + df['Species'].astype('str'))[0]\ndf['Region_Species'].nunique()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"17667"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['height*diameter'] = df['Height'] * df['Diameter']\ndf['height/diameter'] = df['Height'] / df['Diameter']\ndf['log_diameter'] = np.log(df['Diameter'])","execution_count":9,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py:726: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fts = ['Area_Code','Locality_Code','Region_Code','Height','Diameter', 'Species', 'Region_Species']","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in fts:\n  df[f + '_freq'] = df[f].map(df[f].value_counts(normalize = True))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_fts = ['Area_Code', 'Locality_Code', 'Region_Code', 'Species', 'Region_Species', 'Height', 'Diameter']\nnum_fts_2 = ['Height', 'Diameter','height*diameter', 'height/diameter', 'Locality_Code_freq', 'Species_freq']\n\nfor g in tqdm_notebook(cat_fts):\n\n  num_fts = [c for c in num_fts_2 if c != g]\n  grp = df.groupby(g)[num_fts].mean()\n  grp.columns = [c + f'_grpd_by_{g}_mean' for c in grp.columns]\n  df = pd.merge(df, grp, on = g, how = 'left')\n\n  grp = df.groupby(g)[num_fts].std()\n  grp.columns = [c + f'_grpd_by_{g}_std' for c in grp.columns]\n  df = pd.merge(df, grp, on = g, how = 'left')\n\n  grp = df.groupby(g)[num_fts].min()\n  grp.columns = [c + f'_grpd_by_{g}_min' for c in grp.columns]\n  df = pd.merge(df, grp, on = g, how = 'left')\n\n  grp = df.groupby(g)[num_fts].max()\n  grp.columns = [c + f'_grpd_by_{g}_max' for c in grp.columns]\n  df = pd.merge(df, grp, on = g, how = 'left')","execution_count":12,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  after removing the cwd from sys.path.\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd86174297a545d0937df42f7f495de9"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fts = ['Area_Code','Locality_Code','Region_Code','Height','Diameter', 'Species', 'Region_Species']\nfor g in tqdm_notebook(fts):\n  rf = [c for c in fts if c != g]\n  grp = df.groupby(g)[rf].nunique()\n  grp.columns = [c + f'_grpd_by_{g}_nunique' for c in grp.columns]\n  df = pd.merge(df, grp, on = g, how = 'left')","execution_count":13,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51fced62c91743a8ac73d593013adde2"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = df[:train.shape[0]].reset_index(drop = True), df[train.shape[0]:].reset_index(drop = True)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [c for c in train.columns if c not in ['Class', \"Area_Code\", \"Region_Code\", 'Region_Species']]","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oofs = np.zeros((len(train), 8))\npreds = np.zeros((len(test), 8))\nN_SPLITS = 15\nfolds = StratifiedKFold(N_SPLITS, shuffle = True, random_state = 77)\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train['Class'])):\n\n  print(f'\\n\\n Fold {fold_} \\\\n\\n')\n  X_trn, y_trn = train[features].iloc[trn_idx], train[\"Class\"][trn_idx]\n  X_val, y_val = train[features].iloc[val_idx], train[\"Class\"][val_idx]\n\n  clf = LGBMClassifier(n_estimators = 10000, learning_rate = 0.05, colsample_bytree = 0.5, reg_alpha = 0.5, reg_lambda = 1, random_state = 2)\n  #clf = CatBoostClassifier(iterations = 5000, learning_rate = 0.06, random_state=2, reg_lambda=0.5, eval_metric='MultiClass', task_type = 'GPU')\n\n  clf.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], early_stopping_rounds = 150, verbose = 50)\n\n  oofs[val_idx] = clf.predict_proba(X_val)\n  preds += clf.predict_proba(test[features]) / N_SPLITS","execution_count":17,"outputs":[{"output_type":"stream","text":"\n\n Fold 0 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.886885\n[100]\tvalid_0's multi_logloss: 0.793132\n[150]\tvalid_0's multi_logloss: 0.768528\n[200]\tvalid_0's multi_logloss: 0.758423\n[250]\tvalid_0's multi_logloss: 0.753715\n[300]\tvalid_0's multi_logloss: 0.75186\n[350]\tvalid_0's multi_logloss: 0.750641\n[400]\tvalid_0's multi_logloss: 0.753398\n[450]\tvalid_0's multi_logloss: 0.75765\nEarly stopping, best iteration is:\n[348]\tvalid_0's multi_logloss: 0.75064\n\n\n Fold 1 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.860082\n[100]\tvalid_0's multi_logloss: 0.773509\n[150]\tvalid_0's multi_logloss: 0.750835\n[200]\tvalid_0's multi_logloss: 0.742064\n[250]\tvalid_0's multi_logloss: 0.741025\n[300]\tvalid_0's multi_logloss: 0.742805\n[350]\tvalid_0's multi_logloss: 0.744776\nEarly stopping, best iteration is:\n[245]\tvalid_0's multi_logloss: 0.74067\n\n\n Fold 2 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.831143\n[100]\tvalid_0's multi_logloss: 0.730194\n[150]\tvalid_0's multi_logloss: 0.700552\n[200]\tvalid_0's multi_logloss: 0.687575\n[250]\tvalid_0's multi_logloss: 0.682751\n[300]\tvalid_0's multi_logloss: 0.680681\n[350]\tvalid_0's multi_logloss: 0.679119\n[400]\tvalid_0's multi_logloss: 0.678776\n[450]\tvalid_0's multi_logloss: 0.681044\n[500]\tvalid_0's multi_logloss: 0.684496\nEarly stopping, best iteration is:\n[366]\tvalid_0's multi_logloss: 0.677562\n\n\n Fold 3 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.8648\n[100]\tvalid_0's multi_logloss: 0.772793\n[150]\tvalid_0's multi_logloss: 0.745868\n[200]\tvalid_0's multi_logloss: 0.737195\n[250]\tvalid_0's multi_logloss: 0.731778\n[300]\tvalid_0's multi_logloss: 0.730016\n[350]\tvalid_0's multi_logloss: 0.730067\n[400]\tvalid_0's multi_logloss: 0.732884\n[450]\tvalid_0's multi_logloss: 0.733834\nEarly stopping, best iteration is:\n[317]\tvalid_0's multi_logloss: 0.72862\n\n\n Fold 4 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.825893\n[100]\tvalid_0's multi_logloss: 0.72788\n[150]\tvalid_0's multi_logloss: 0.703072\n[200]\tvalid_0's multi_logloss: 0.691747\n[250]\tvalid_0's multi_logloss: 0.687673\n[300]\tvalid_0's multi_logloss: 0.687175\n[350]\tvalid_0's multi_logloss: 0.688256\n[400]\tvalid_0's multi_logloss: 0.691161\nEarly stopping, best iteration is:\n[299]\tvalid_0's multi_logloss: 0.687172\n\n\n Fold 5 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.85379\n[100]\tvalid_0's multi_logloss: 0.763765\n[150]\tvalid_0's multi_logloss: 0.734482\n[200]\tvalid_0's multi_logloss: 0.720742\n[250]\tvalid_0's multi_logloss: 0.716945\n[300]\tvalid_0's multi_logloss: 0.715145\n[350]\tvalid_0's multi_logloss: 0.71595\n[400]\tvalid_0's multi_logloss: 0.71698\nEarly stopping, best iteration is:\n[298]\tvalid_0's multi_logloss: 0.714914\n\n\n Fold 6 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.839645\n[100]\tvalid_0's multi_logloss: 0.744848\n[150]\tvalid_0's multi_logloss: 0.71734\n[200]\tvalid_0's multi_logloss: 0.702555\n[250]\tvalid_0's multi_logloss: 0.693773\n[300]\tvalid_0's multi_logloss: 0.691551\n[350]\tvalid_0's multi_logloss: 0.693074\n[400]\tvalid_0's multi_logloss: 0.694269\n[450]\tvalid_0's multi_logloss: 0.695343\nEarly stopping, best iteration is:\n[306]\tvalid_0's multi_logloss: 0.69116\n\n\n Fold 7 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.896553\n[100]\tvalid_0's multi_logloss: 0.822453\n[150]\tvalid_0's multi_logloss: 0.802269\n[200]\tvalid_0's multi_logloss: 0.800564\n[250]\tvalid_0's multi_logloss: 0.80083\n[300]\tvalid_0's multi_logloss: 0.804478\n[350]\tvalid_0's multi_logloss: 0.809529\nEarly stopping, best iteration is:\n[222]\tvalid_0's multi_logloss: 0.799229\n\n\n Fold 8 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.842152\n[100]\tvalid_0's multi_logloss: 0.752146\n[150]\tvalid_0's multi_logloss: 0.732063\n[200]\tvalid_0's multi_logloss: 0.724393\n[250]\tvalid_0's multi_logloss: 0.720374\n[300]\tvalid_0's multi_logloss: 0.721571\n[350]\tvalid_0's multi_logloss: 0.725345\n[400]\tvalid_0's multi_logloss: 0.728813\nEarly stopping, best iteration is:\n[260]\tvalid_0's multi_logloss: 0.71961\n\n\n Fold 9 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.868037\n[100]\tvalid_0's multi_logloss: 0.786739\n[150]\tvalid_0's multi_logloss: 0.764505\n[200]\tvalid_0's multi_logloss: 0.758513\n[250]\tvalid_0's multi_logloss: 0.756394\n[300]\tvalid_0's multi_logloss: 0.755559\n[350]\tvalid_0's multi_logloss: 0.757383\n[400]\tvalid_0's multi_logloss: 0.760782\nEarly stopping, best iteration is:\n[296]\tvalid_0's multi_logloss: 0.755144\n\n\n Fold 10 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.846878\n[100]\tvalid_0's multi_logloss: 0.761676\n[150]\tvalid_0's multi_logloss: 0.744157\n[200]\tvalid_0's multi_logloss: 0.74203\n[250]\tvalid_0's multi_logloss: 0.741981\n[300]\tvalid_0's multi_logloss: 0.743829\n[350]\tvalid_0's multi_logloss: 0.746066\nEarly stopping, best iteration is:\n[243]\tvalid_0's multi_logloss: 0.741399\n\n\n Fold 11 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.858164\n[100]\tvalid_0's multi_logloss: 0.767937\n[150]\tvalid_0's multi_logloss: 0.747958\n[200]\tvalid_0's multi_logloss: 0.743097\n[250]\tvalid_0's multi_logloss: 0.741222\n[300]\tvalid_0's multi_logloss: 0.743019\n[350]\tvalid_0's multi_logloss: 0.748\n[400]\tvalid_0's multi_logloss: 0.752529\nEarly stopping, best iteration is:\n[256]\tvalid_0's multi_logloss: 0.740837\n\n\n Fold 12 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.817685\n[100]\tvalid_0's multi_logloss: 0.723862\n[150]\tvalid_0's multi_logloss: 0.697099\n[200]\tvalid_0's multi_logloss: 0.687694\n[250]\tvalid_0's multi_logloss: 0.684869\n[300]\tvalid_0's multi_logloss: 0.68286\n[350]\tvalid_0's multi_logloss: 0.682109\n[400]\tvalid_0's multi_logloss: 0.683566\n[450]\tvalid_0's multi_logloss: 0.685622\n[500]\tvalid_0's multi_logloss: 0.690157\nEarly stopping, best iteration is:\n[352]\tvalid_0's multi_logloss: 0.681731\n\n\n Fold 13 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.861501\n[100]\tvalid_0's multi_logloss: 0.773922\n[150]\tvalid_0's multi_logloss: 0.751544\n[200]\tvalid_0's multi_logloss: 0.748497\n[250]\tvalid_0's multi_logloss: 0.747439\n[300]\tvalid_0's multi_logloss: 0.749171\n[350]\tvalid_0's multi_logloss: 0.752761\nEarly stopping, best iteration is:\n[237]\tvalid_0's multi_logloss: 0.746405\n\n\n Fold 14 \\n\n\nTraining until validation scores don't improve for 150 rounds\n[50]\tvalid_0's multi_logloss: 0.865079\n[100]\tvalid_0's multi_logloss: 0.774351\n[150]\tvalid_0's multi_logloss: 0.748384\n[200]\tvalid_0's multi_logloss: 0.743533\n[250]\tvalid_0's multi_logloss: 0.738002\n[300]\tvalid_0's multi_logloss: 0.736435\n[350]\tvalid_0's multi_logloss: 0.738722\n[400]\tvalid_0's multi_logloss: 0.741389\n[450]\tvalid_0's multi_logloss: 0.743008\nEarly stopping, best iteration is:\n[300]\tvalid_0's multi_logloss: 0.736435\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_val_score = log_loss(train['Class'], oofs)\nprint(f'Final Log loss: {oof_val_score}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss[ss.columns.tolist()] = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}